{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Config.Dataset.example import load_dataset\n",
    "from Config.Model.example import ComposedModel\n",
    "from torch.utils.data import DataLoader\n",
    "from Pruning.greg import GReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset()\n",
    "model = ComposedModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "greg = GReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([1024, 512, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([2048, 1024, 1, 1])\n",
      "torch.Size([512, 2048, 1, 1])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([512, 2048, 1, 1])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([1000, 2048])\n",
      "Register layer index and kernel shape:\n",
      "[ 0]                 conv1 -- kernel_shape: torch.Size([64, 3, 7, 7])\n",
      "[ 1]        layer1.0.conv1 -- kernel_shape: torch.Size([64, 64, 1, 1])\n",
      "[ 2]        layer1.0.conv2 -- kernel_shape: torch.Size([64, 64, 3, 3])\n",
      "[ 3]        layer1.0.conv3 -- kernel_shape: torch.Size([256, 64, 1, 1])\n",
      "[ 3] layer1.0.downsample.0 -- kernel_shape: torch.Size([256, 64, 1, 1])\n",
      "[ 4]        layer1.1.conv1 -- kernel_shape: torch.Size([64, 256, 1, 1])\n",
      "[ 5]        layer1.1.conv2 -- kernel_shape: torch.Size([64, 64, 3, 3])\n",
      "[ 6]        layer1.1.conv3 -- kernel_shape: torch.Size([256, 64, 1, 1])\n",
      "[ 7]        layer1.2.conv1 -- kernel_shape: torch.Size([64, 256, 1, 1])\n",
      "[ 8]        layer1.2.conv2 -- kernel_shape: torch.Size([64, 64, 3, 3])\n",
      "[ 9]        layer1.2.conv3 -- kernel_shape: torch.Size([256, 64, 1, 1])\n",
      "[10]        layer2.0.conv1 -- kernel_shape: torch.Size([128, 256, 1, 1])\n",
      "[11]        layer2.0.conv2 -- kernel_shape: torch.Size([128, 128, 3, 3])\n",
      "[12]        layer2.0.conv3 -- kernel_shape: torch.Size([512, 128, 1, 1])\n",
      "[12] layer2.0.downsample.0 -- kernel_shape: torch.Size([512, 256, 1, 1])\n",
      "[13]        layer2.1.conv1 -- kernel_shape: torch.Size([128, 512, 1, 1])\n",
      "[14]        layer2.1.conv2 -- kernel_shape: torch.Size([128, 128, 3, 3])\n",
      "[15]        layer2.1.conv3 -- kernel_shape: torch.Size([512, 128, 1, 1])\n",
      "[16]        layer2.2.conv1 -- kernel_shape: torch.Size([128, 512, 1, 1])\n",
      "[17]        layer2.2.conv2 -- kernel_shape: torch.Size([128, 128, 3, 3])\n",
      "[18]        layer2.2.conv3 -- kernel_shape: torch.Size([512, 128, 1, 1])\n",
      "[19]        layer2.3.conv1 -- kernel_shape: torch.Size([128, 512, 1, 1])\n",
      "[20]        layer2.3.conv2 -- kernel_shape: torch.Size([128, 128, 3, 3])\n",
      "[21]        layer2.3.conv3 -- kernel_shape: torch.Size([512, 128, 1, 1])\n",
      "[22]        layer3.0.conv1 -- kernel_shape: torch.Size([256, 512, 1, 1])\n",
      "[23]        layer3.0.conv2 -- kernel_shape: torch.Size([256, 256, 3, 3])\n",
      "[24]        layer3.0.conv3 -- kernel_shape: torch.Size([1024, 256, 1, 1])\n",
      "[24] layer3.0.downsample.0 -- kernel_shape: torch.Size([1024, 512, 1, 1])\n",
      "[25]        layer3.1.conv1 -- kernel_shape: torch.Size([256, 1024, 1, 1])\n",
      "[26]        layer3.1.conv2 -- kernel_shape: torch.Size([256, 256, 3, 3])\n",
      "[27]        layer3.1.conv3 -- kernel_shape: torch.Size([1024, 256, 1, 1])\n",
      "[28]        layer3.2.conv1 -- kernel_shape: torch.Size([256, 1024, 1, 1])\n",
      "[29]        layer3.2.conv2 -- kernel_shape: torch.Size([256, 256, 3, 3])\n",
      "[30]        layer3.2.conv3 -- kernel_shape: torch.Size([1024, 256, 1, 1])\n",
      "[31]        layer3.3.conv1 -- kernel_shape: torch.Size([256, 1024, 1, 1])\n",
      "[32]        layer3.3.conv2 -- kernel_shape: torch.Size([256, 256, 3, 3])\n",
      "[33]        layer3.3.conv3 -- kernel_shape: torch.Size([1024, 256, 1, 1])\n",
      "[34]        layer3.4.conv1 -- kernel_shape: torch.Size([256, 1024, 1, 1])\n",
      "[35]        layer3.4.conv2 -- kernel_shape: torch.Size([256, 256, 3, 3])\n",
      "[36]        layer3.4.conv3 -- kernel_shape: torch.Size([1024, 256, 1, 1])\n",
      "[37]        layer3.5.conv1 -- kernel_shape: torch.Size([256, 1024, 1, 1])\n",
      "[38]        layer3.5.conv2 -- kernel_shape: torch.Size([256, 256, 3, 3])\n",
      "[39]        layer3.5.conv3 -- kernel_shape: torch.Size([1024, 256, 1, 1])\n",
      "[40]        layer4.0.conv1 -- kernel_shape: torch.Size([512, 1024, 1, 1])\n",
      "[41]        layer4.0.conv2 -- kernel_shape: torch.Size([512, 512, 3, 3])\n",
      "[42]        layer4.0.conv3 -- kernel_shape: torch.Size([2048, 512, 1, 1])\n",
      "[42] layer4.0.downsample.0 -- kernel_shape: torch.Size([2048, 1024, 1, 1])\n",
      "[43]        layer4.1.conv1 -- kernel_shape: torch.Size([512, 2048, 1, 1])\n",
      "[44]        layer4.1.conv2 -- kernel_shape: torch.Size([512, 512, 3, 3])\n",
      "[45]        layer4.1.conv3 -- kernel_shape: torch.Size([2048, 512, 1, 1])\n",
      "[46]        layer4.2.conv1 -- kernel_shape: torch.Size([512, 2048, 1, 1])\n",
      "[47]        layer4.2.conv2 -- kernel_shape: torch.Size([512, 512, 3, 3])\n",
      "[48]        layer4.2.conv3 -- kernel_shape: torch.Size([2048, 512, 1, 1])\n",
      "[49]                    fc -- kernel_shape: torch.Size([1000, 2048])\n",
      "\n",
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer1.0\n",
      "layer1.0.conv1\n",
      "layer1.0.bn1\n",
      "layer1.0.conv2\n",
      "layer1.0.bn2\n",
      "layer1.0.conv3\n",
      "layer1.0.bn3\n",
      "layer1.0.relu\n",
      "layer1.0.downsample\n",
      "layer1.0.downsample.0\n",
      "layer1.0.downsample.1\n",
      "layer1.1\n",
      "layer1.1.conv1\n",
      "layer1.1.bn1\n",
      "layer1.1.conv2\n",
      "layer1.1.bn2\n",
      "layer1.1.conv3\n",
      "layer1.1.bn3\n",
      "layer1.1.relu\n",
      "layer1.2\n",
      "layer1.2.conv1\n",
      "layer1.2.bn1\n",
      "layer1.2.conv2\n",
      "layer1.2.bn2\n",
      "layer1.2.conv3\n",
      "layer1.2.bn3\n",
      "layer1.2.relu\n",
      "layer2\n",
      "layer2.0\n",
      "layer2.0.conv1\n",
      "layer2.0.bn1\n",
      "layer2.0.conv2\n",
      "layer2.0.bn2\n",
      "layer2.0.conv3\n",
      "layer2.0.bn3\n",
      "layer2.0.relu\n",
      "layer2.0.downsample\n",
      "layer2.0.downsample.0\n",
      "layer2.0.downsample.1\n",
      "layer2.1\n",
      "layer2.1.conv1\n",
      "layer2.1.bn1\n",
      "layer2.1.conv2\n",
      "layer2.1.bn2\n",
      "layer2.1.conv3\n",
      "layer2.1.bn3\n",
      "layer2.1.relu\n",
      "layer2.2\n",
      "layer2.2.conv1\n",
      "layer2.2.bn1\n",
      "layer2.2.conv2\n",
      "layer2.2.bn2\n",
      "layer2.2.conv3\n",
      "layer2.2.bn3\n",
      "layer2.2.relu\n",
      "layer2.3\n",
      "layer2.3.conv1\n",
      "layer2.3.bn1\n",
      "layer2.3.conv2\n",
      "layer2.3.bn2\n",
      "layer2.3.conv3\n",
      "layer2.3.bn3\n",
      "layer2.3.relu\n",
      "layer3\n",
      "layer3.0\n",
      "layer3.0.conv1\n",
      "layer3.0.bn1\n",
      "layer3.0.conv2\n",
      "layer3.0.bn2\n",
      "layer3.0.conv3\n",
      "layer3.0.bn3\n",
      "layer3.0.relu\n",
      "layer3.0.downsample\n",
      "layer3.0.downsample.0\n",
      "layer3.0.downsample.1\n",
      "layer3.1\n",
      "layer3.1.conv1\n",
      "layer3.1.bn1\n",
      "layer3.1.conv2\n",
      "layer3.1.bn2\n",
      "layer3.1.conv3\n",
      "layer3.1.bn3\n",
      "layer3.1.relu\n",
      "layer3.2\n",
      "layer3.2.conv1\n",
      "layer3.2.bn1\n",
      "layer3.2.conv2\n",
      "layer3.2.bn2\n",
      "layer3.2.conv3\n",
      "layer3.2.bn3\n",
      "layer3.2.relu\n",
      "layer3.3\n",
      "layer3.3.conv1\n",
      "layer3.3.bn1\n",
      "layer3.3.conv2\n",
      "layer3.3.bn2\n",
      "layer3.3.conv3\n",
      "layer3.3.bn3\n",
      "layer3.3.relu\n",
      "layer3.4\n",
      "layer3.4.conv1\n",
      "layer3.4.bn1\n",
      "layer3.4.conv2\n",
      "layer3.4.bn2\n",
      "layer3.4.conv3\n",
      "layer3.4.bn3\n",
      "layer3.4.relu\n",
      "layer3.5\n",
      "layer3.5.conv1\n",
      "layer3.5.bn1\n",
      "layer3.5.conv2\n",
      "layer3.5.bn2\n",
      "layer3.5.conv3\n",
      "layer3.5.bn3\n",
      "layer3.5.relu\n",
      "layer4\n",
      "layer4.0\n",
      "layer4.0.conv1\n",
      "layer4.0.bn1\n",
      "layer4.0.conv2\n",
      "layer4.0.bn2\n",
      "layer4.0.conv3\n",
      "layer4.0.bn3\n",
      "layer4.0.relu\n",
      "layer4.0.downsample\n",
      "layer4.0.downsample.0\n",
      "layer4.0.downsample.1\n",
      "layer4.1\n",
      "layer4.1.conv1\n",
      "layer4.1.bn1\n",
      "layer4.1.conv2\n",
      "layer4.1.bn2\n",
      "layer4.1.conv3\n",
      "layer4.1.bn3\n",
      "layer4.1.relu\n",
      "layer4.2\n",
      "layer4.2.conv1\n",
      "layer4.2.bn1\n",
      "layer4.2.conv2\n",
      "layer4.2.bn2\n",
      "layer4.2.conv3\n",
      "layer4.2.bn3\n",
      "layer4.2.relu\n",
      "avgpool\n",
      "fc\n",
      "{'conv1': '[', 'layer1.0.conv1': '0', 'layer1.0.conv2': '0', 'layer1.0.conv3': '0', 'layer1.0.downsample.0': '0', 'layer1.1.conv1': '0', 'layer1.1.conv2': '0', 'layer1.1.conv3': '0', 'layer1.2.conv1': '0', 'layer1.2.conv2': '0', 'layer1.2.conv3': '0', 'layer2.0.conv1': ',', 'layer2.0.conv2': ',', 'layer2.0.conv3': ',', 'layer2.0.downsample.0': ',', 'layer2.1.conv1': ',', 'layer2.1.conv2': ',', 'layer2.1.conv3': ',', 'layer2.2.conv1': ',', 'layer2.2.conv2': ',', 'layer2.2.conv3': ',', 'layer2.3.conv1': ',', 'layer2.3.conv2': ',', 'layer2.3.conv3': ',', 'layer3.0.conv1': '0', 'layer3.0.conv2': '0', 'layer3.0.conv3': '0', 'layer3.0.downsample.0': '0', 'layer3.1.conv1': '0', 'layer3.1.conv2': '0', 'layer3.1.conv3': '0', 'layer3.2.conv1': '0', 'layer3.2.conv2': '0', 'layer3.2.conv3': '0', 'layer3.3.conv1': '0', 'layer3.3.conv2': '0', 'layer3.3.conv3': '0', 'layer3.4.conv1': '0', 'layer3.4.conv2': '0', 'layer3.4.conv3': '0', 'layer3.5.conv1': '0', 'layer3.5.conv2': '0', 'layer3.5.conv3': '0', 'layer4.0.conv1': '.', 'layer4.0.conv2': '.', 'layer4.0.conv3': '.', 'layer4.0.downsample.0': '.', 'layer4.1.conv1': '.', 'layer4.1.conv2': '.', 'layer4.1.conv3': '.', 'layer4.2.conv1': '.', 'layer4.2.conv2': '.', 'layer4.2.conv3': '.', 'fc': '6'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m greg\u001b[39m.\u001b[39;49m_init_model(model, train_dataloader,test_loader\u001b[39m=\u001b[39;49mtest_dataloader)\n",
      "File \u001b[0;32m~/Documents/GitHub/Neural-testing/Pruning/greg.py:150\u001b[0m, in \u001b[0;36mGReg._init_model\u001b[0;34m(self, model, train_loader_prune, test_loader, n_conv_within_block, res, stage_pr, skip_layers, pick_pruned)\u001b[0m\n\u001b[1;32m    148\u001b[0m passer\u001b[39m.\u001b[39mskip_layers \u001b[39m=\u001b[39m skip_layers\n\u001b[1;32m    149\u001b[0m passer\u001b[39m.\u001b[39mpick_pruned \u001b[39m=\u001b[39m pick_pruned\n\u001b[0;32m--> 150\u001b[0m pruner \u001b[39m=\u001b[39m Pruner(model\u001b[39m.\u001b[39;49mmodel,passer)\n\u001b[1;32m    151\u001b[0m pruner\u001b[39m.\u001b[39mprune()\n\u001b[1;32m    152\u001b[0m mask \u001b[39m=\u001b[39m pruner\u001b[39m.\u001b[39mmask\n",
      "File \u001b[0;32m~/Documents/GitHub/Neural-testing/Pruning/reg_pruner.py:43\u001b[0m, in \u001b[0;36mPruner.__init__\u001b[0;34m(self, model, passer, reg_granularity_recover, reg_granularity_prune, reg_granularity_pick, reg_upper_limit_pick, reg_upper_limit, lr_prune, momentum, weight_decay, test_interval, update_reg_interval, stabilize_reg_interval)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_reg_interval \u001b[39m=\u001b[39m update_reg_interval\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstabilize_reg_interval \u001b[39m=\u001b[39m stabilize_reg_interval\n\u001b[0;32m---> 43\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_kept_wg_L1()\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpruned_wg\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpruned_wg_L1[k] \u001b[39m=\u001b[39m v\n",
      "File \u001b[0;32m~/Documents/GitHub/Neural-testing/Pruning/meta_pruner.py:210\u001b[0m, in \u001b[0;36mMetaPruner._get_kept_wg_L1\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(m, nn\u001b[39m.\u001b[39mConv2d) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(m, nn\u001b[39m.\u001b[39mLinear):\n\u001b[1;32m    209\u001b[0m     score \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpruned_wg[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pick_pruned(score, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpr[name], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpick_pruned)\n\u001b[1;32m    211\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkept_wg[name] \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(score)) \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpruned_wg[name]]\n",
      "File \u001b[0;32m~/Documents/GitHub/Neural-testing/Pruning/meta_pruner.py:69\u001b[0m, in \u001b[0;36mMetaPruner._pick_pruned\u001b[0;34m(self, w_abs, pr, mode)\u001b[0m\n\u001b[1;32m     67\u001b[0m w_abs_list \u001b[39m=\u001b[39m w_abs\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     68\u001b[0m n_wg \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(w_abs_list)\n\u001b[0;32m---> 69\u001b[0m n_pruned \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(ceil(pr \u001b[39m*\u001b[39;49m n_wg), n_wg \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m# do not prune all\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrand\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     71\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mpermutation(n_wg)[:n_pruned]\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "greg._init_model(model, train_dataloader,test_loader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
